"""High level service that enriches wine entries with contextual information."""

from __future__ import annotations

import json
import logging
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Iterable, List, Optional
from urllib.parse import urlparse

import bleach
import requests

from openai import OpenAI, OpenAIError
from app.field_config import FIELD_STORAGE_MAP, iter_fields

logger = logging.getLogger(__name__)


@dataclass
class InsightData:
    """Transport object describing an insight about a wine."""

    category: Optional[str]
    title: Optional[str]
    content: str
    source_name: Optional[str]
    source_url: Optional[str]
    weight: int = 0


@dataclass
class EnrichmentResult:
    """Aggregate payload produced for a wine enrichment run."""

    insights: List[InsightData]
    label_image_data: Optional[str] = None
    label_image_mime_type: str = "image/png"

    def has_payload(self) -> bool:
        return bool(self.insights or self.label_image_data)


class WineInfoService:
    """Aggregate data from public APIs (OpenAI)."""

    def __init__(
        self,
        session: Optional[requests.Session] = None,
        *,
        openai_client: Optional[OpenAI] = None,
        openai_model: Optional[str] = None,
        openai_image_model: Optional[str] = None,
        openai_source_name: str = "OpenAI",
        log_openai_payloads: bool = False,
    ) -> None:
        self.session = session or requests.Session()
        self.openai_client = openai_client
        self.openai_model = openai_model
        self.openai_image_model = openai_image_model
        self.openai_source_name = openai_source_name
        self.log_openai_payloads = log_openai_payloads

    @classmethod
    def from_app(cls, app) -> "WineInfoService":
        """Factory that uses the Flask app configuration to bootstrap providers."""
        logger.info("üîß Initialisation de WineInfoService depuis l'application Flask")

        openai_client = None
        client_kwargs = {}

        api_key = (app.config.get("OPENAI_API_KEY") or "").strip()
        base_url = (app.config.get("OPENAI_BASE_URL") or "").strip()

        logger.debug("Configuration OpenAI - API Key pr√©sente: %s, Base URL: %s",
                    bool(api_key), base_url or "par d√©faut")

        if api_key:
            client_kwargs["api_key"] = api_key

        if base_url:
            client_kwargs["base_url"] = base_url.rstrip("/")

        if client_kwargs:
            try:
                openai_client = OpenAI(**client_kwargs)
                logger.info("‚úÖ Client OpenAI initialis√© avec succ√®s")
            except OpenAIError as exc:  # pragma: no cover - defensive logging
                logger.warning("‚ùå Impossible d'initialiser le client OpenAI : %s", exc)

        openai_model = (
            (app.config.get("OPENAI_MODEL") or "").strip()
            or (app.config.get("OPENAI_FREE_MODEL") or "").strip()
            or "gpt-4o-mini"
        )
        logger.info("üìã Mod√®le OpenAI configur√©: %s", openai_model)

        raw_image_model = (app.config.get("OPENAI_IMAGE_MODEL") or "").strip()
        openai_image_model = raw_image_model or ("dall-e-2" if openai_client else None)
        if openai_image_model:
            logger.info("üñºÔ∏è Mod√®le d'image OpenAI configur√©: %s", openai_image_model)
        else:
            logger.info("üñºÔ∏è G√©n√©ration d'√©tiquettes d√©sactiv√©e (aucun mod√®le configur√©)")

        source_name = (app.config.get("OPENAI_SOURCE_NAME") or "OpenAI").strip() or "OpenAI"
        logger.debug("Source name: %s", source_name)

        return cls(
            openai_client=openai_client,
            openai_model=openai_model,
            openai_image_model=openai_image_model,
            openai_source_name=source_name,
            log_openai_payloads=bool(app.config.get("OPENAI_LOG_REQUESTS")),
        )

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    def fetch(self, wine) -> EnrichmentResult:
        """Return insights and optional label artwork for the provided wine."""
        logger.info("=" * 80)
        logger.info("üç∑ D√©but de la r√©cup√©ration d'informations pour le vin: %s", wine.name)

        query = self._build_query(wine)
        logger.debug("üîç Requ√™te construite: '%s'", query)

        if not query:
            logger.warning("‚ö†Ô∏è Requ√™te vide, abandon de la r√©cup√©ration")
            return EnrichmentResult(insights=[])

        logger.info("üìä Fetching contextual data for wine: %s", query)
        insights: List[InsightData] = []
        label_image_data: Optional[str] = None

        providers = []

        if self.openai_client:
            logger.info("ü§ñ Client OpenAI disponible, ajout du provider OpenAI")
            providers.append(("openai", lambda: self._openai_insights(wine, query)))
        else:
            logger.info("‚ö†Ô∏è Client OpenAI non disponible, skip du provider OpenAI")

        logger.info("üì° Nombre de providers √† interroger: %d", len(providers))

        for provider_name, provider_callable in providers:
            logger.info("üîÑ Interrogation du provider: %s", provider_name)
            try:
                provider_insights = list(provider_callable())
                insights.extend(provider_insights)
                logger.info("‚úÖ Provider %s: %d insights r√©cup√©r√©s",
                          provider_name, len(provider_insights))
            except Exception as exc:  # pragma: no cover - defensive logging
                logger.exception("‚ùå Provider %s failed for %s: %s",
                               provider_name, query, exc)

        logger.info("üîÑ D√©duplication des insights (%d avant d√©duplication)", len(insights))
        deduplicated = self._deduplicate(insights)
        logger.info("‚úÖ R√©cup√©ration termin√©e: %d insights uniques", len(deduplicated))

        if self.openai_client and self.openai_image_model:
            logger.info("üñºÔ∏è Tentative de g√©n√©ration d'une √©tiquette stylis√©e")
            label_image_data = self._openai_label_image(wine, query)
            if label_image_data:
                logger.info("üñºÔ∏è √âtiquette g√©n√©r√©e avec succ√®s (%d caract√®res)", len(label_image_data))
            else:
                logger.info("‚ö†Ô∏è Aucune √©tiquette g√©n√©r√©e pour ce vin")

        logger.info("=" * 80)

        return EnrichmentResult(insights=deduplicated, label_image_data=label_image_data)

    # ------------------------------------------------------------------
    # Providers
    # ------------------------------------------------------------------
    def _openai_insights(self, wine, query: str) -> Iterable[InsightData]:
        logger.info("ü§ñ OpenAI: d√©but de la g√©n√©ration d'insights")

        if not self.openai_client:
            logger.warning("‚ö†Ô∏è OpenAI: client non disponible")
            return []

        if not self.openai_model:
            logger.info("‚ö†Ô∏è Aucun mod√®le OpenAI configur√© ; abandon de la requ√™te")
            return []

        logger.debug("ü§ñ OpenAI: mod√®le utilis√©: %s", self.openai_model)

        details = [f"Nom: {wine.name}"]
        extra_attrs = getattr(wine, "extra_attributes", {}) or {}

        year = extra_attrs.get("year")
        if year:
            details.append(f"Mill√©sime: {year}")

        region = extra_attrs.get("region")
        if region:
            details.append(f"R√©gion: {region}")

        grape = extra_attrs.get("grape")
        if grape:
            details.append(f"C√©page: {grape}")

        volume_ml = extra_attrs.get("volume_ml")
        if volume_ml:
            details.append(f"Contenance: {volume_ml} mL")
        if getattr(wine, "subcategory", None):
            subcategory_name = wine.subcategory.name
            category_name = wine.subcategory.category.name if wine.subcategory.category else None
            if category_name:
                details.append(f"Type: {category_name} - {subcategory_name}")
            else:
                details.append(f"Type: {subcategory_name}")
        description = extra_attrs.get("description")
        if description:
            details.append(
                f"Description utilisateur: {self._truncate(str(description), 280)}"
            )
        try:
            extra_attributes = getattr(wine, "extra_attributes", {}) or {}
            for field in iter_fields():
                if field.name in {"region", "grape", "year", "volume_ml", "description"}:
                    continue
                storage = FIELD_STORAGE_MAP.get(field.name)
                if storage:
                    value = getattr(wine, storage.get("attribute"), None)
                else:
                    value = extra_attributes.get(field.name)
                if value:
                    details.append(f"{field.label}: {value}")
        except Exception:  # pragma: no cover - best effort enrichment
            pass
        details.append(f"Requ√™te utilis√©e: {query}")

        logger.debug("üìã OpenAI: d√©tails du vin collect√©s: %s", ", ".join(details))

        system_prompt = (
            "Tu es un assistant sommelier charg√© d'enrichir la fiche d'un alcool. "
            "Tu r√©ponds exclusivement en fran√ßais et fournis des informations fiables, "
            "concis, adapt√©es √† un public de passionn√©s."
        )

        user_prompt = (
            "Voici les informations connues sur l'alcool :\n"
            + "\n".join(f"- {line}" for line in details if line)
            + "\n\n"
            "Compl√®te avec 4 √† 6 √©clairages distincts (estimation du prix actuel, histoire du domaine, profil aromatique, accords mets et vins, potentiel de garde, etc.). "
            "Chaque √©clairage doit tenir en 2 √† 4 phrases maximum."
            "Structure ta r√©ponse au format JSON selon le sch√©ma demand√©, sans texte additionnel."
        )

        schema = {
            "type": "object",
            "additionalProperties": False,
            "properties": {
                "insights": {
                    "type": "array",
                    "minItems": 1,
                    "maxItems": 5,
                    "items": {
                        "type": "object",
                        "additionalProperties": False,
                        "properties": {
                            "category": {"type": "string"},
                            "title": {"type": "string"},
                            "content": {"type": "string"},
                            "source": {"type": "string"},
                            "weight": {"type": "integer"},
                        },
                        "required": ["category", "title", "content", "source", "weight"],
                    },
                }
            },
            "required": ["insights"],
        }

        logger.info("üì§ OpenAI: envoi de la requ√™te √† l'API")
        logger.debug(
            "Longueurs des prompts - syst√®me: %d, utilisateur: %d",
            len(system_prompt),
            len(user_prompt),
        )

        try:
            # Utilisation de l'API Responses avec le type correct 'input_text'
            response = self.openai_client.responses.create(
                model=self.openai_model,
                input=[
                    {
                        "role": "system",
                        "content": [{"type": "input_text", "text": system_prompt.strip()}],
                    },
                    {
                        "role": "user",
                        "content": [{"type": "input_text", "text": user_prompt.strip()}],
                    },
                ],
                text={
                    "format": {
                        "type": "json_schema",
                        "name": "wine_enrichment",
                        "schema": schema
                    },
                },
                max_output_tokens=900,
            )
            logger.info("‚úÖ OpenAI: r√©ponse re√ßue de l'API")

            # Enregistrement de la requ√™te et de la r√©ponse
            self._log_openai_request_response(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                schema=schema,
                response=response,
                error=None
            )

        except OpenAIError as exc:
            logger.warning("‚ùå Requ√™te OpenAI √©chou√©e : %s", exc)
            self._log_openai_request_response(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                schema=schema,
                response=None,
                error=str(exc)
            )
            return []
        except Exception as exc:  # pragma: no cover - defensive logging
            logger.warning("‚ùå Erreur inattendue lors de l'appel OpenAI : %s", exc)
            self._log_openai_request_response(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                schema=schema,
                response=None,
                error=f"Unexpected error: {exc}"
            )
            return []

        logger.debug("üîç OpenAI: parsing de la r√©ponse")
        payload = self._parse_openai_payload(response)

        if not payload:
            logger.warning("‚ö†Ô∏è OpenAI: impossible de parser la r√©ponse")
            return []

        items = payload.get("insights") or []
        logger.info("üìä OpenAI: %d insight(s) trouv√©(s) dans la r√©ponse", len(items))
        insights: List[InsightData] = []
        for index, item in enumerate(items[:5]):
            raw_content = (item.get("content") or "").strip()
            if not raw_content:
                logger.debug("‚ö†Ô∏è OpenAI: insight #%d ignor√© (contenu vide)", index)
                continue

            category = self._sanitize_text(item.get("category")) or "analyse"
            logger.debug("‚úÖ OpenAI: cr√©ation insight #%d - cat√©gorie: %s", index, category)
            title = self._sanitize_text(item.get("title"))
            source_name = (
                self._sanitize_text(item.get("source"))
                or self.openai_source_name
            )

            weight = item.get("weight")
            try:
                weight_value = int(weight)
            except (TypeError, ValueError):
                weight_value = max(1, 10 - index)
            weight_value = max(1, min(10, weight_value))

            insights.append(
                InsightData(
                    category=category,
                    title=title,
                    content=self._sanitize_content(self._truncate(raw_content, 900)),
                    source_name=source_name,
                    source_url=self._sanitize_source_url(item.get("url") or item.get("source_url")),
                    weight=weight_value,
                )
            )

        logger.info("‚úÖ OpenAI: %d insight(s) cr√©√©(s) avec succ√®s", len(insights))
        return insights

    def _openai_label_image(self, wine, query: str) -> Optional[str]:
        if not self.openai_client or not self.openai_image_model:
            return None

        prompt = self._build_label_prompt(wine, query)
        if not prompt:
            return None

        try:
            response = self.openai_client.images.generate(
                model=self.openai_image_model,
                prompt=prompt,
                size="1024x1024",
                n=1,
            )
        except OpenAIError as exc:
            logger.warning("‚ùå OpenAI image generation failed: %s", exc)
            return None
        except Exception as exc:  # pragma: no cover - defensive logging
            logger.warning("‚ùå Unexpected error during image generation: %s", exc)
            return None

        payload = getattr(response, "data", None) or []
        if not payload:
            logger.info("‚ö†Ô∏è OpenAI image generation returned no data")
            return None

        first_item = payload[0]
        image_b64 = None

        if isinstance(first_item, dict):
            image_b64 = first_item.get("b64_json")
        else:
            image_b64 = getattr(first_item, "b64_json", None)

        if not image_b64:
            logger.info("‚ö†Ô∏è OpenAI image payload missing b64_json field")
            return None

        return image_b64.strip()

    def _build_label_prompt(self, wine, query: str) -> str:
        details = [
            f"Nom du vin : {wine.name}" if wine.name else None,
        ]

        extras = getattr(wine, "extra_attributes", {}) or {}

        if extras.get("year"):
            details.append(f"Mill√©sime : {extras.get('year')}")
        if extras.get("region"):
            details.append(f"R√©gion : {extras.get('region')}")
        if extras.get("grape"):
            details.append(f"C√©page : {extras.get('grape')}")
        if extras.get("description"):
            details.append(
                f"Notes du propri√©taire : {self._truncate(str(extras.get('description')), 120)}"
            )
        if getattr(wine, "subcategory", None):
            subtype = wine.subcategory
            if subtype and subtype.category:
                details.append(
                    f"Cat√©gorie : {subtype.category.name} / {subtype.name}"
                )
            elif subtype:
                details.append(f"Cat√©gorie : {subtype.name}")

        detail_text = "; ".join(filter(None, details))

        base_prompt = (
            "Design a flat, poster-like illustration of a refined French wine label. "
            "Use elegant typography, subtle texture, and muted natural colors. "
            "Show only the label on a neutral background, no bottle photo. "
            "Incorporate the following information in French: "
        )

        prompt = f"{base_prompt}{detail_text}. Requ√™te de r√©f√©rence: {query}."
        return prompt.strip()

    def _parse_openai_payload(self, response) -> Optional[dict]:
        logger.debug("üîç Parsing de la r√©ponse OpenAI")

        if response is None:
            logger.debug("‚ö†Ô∏è R√©ponse OpenAI est None")
            return None

        text_payload = getattr(response, "output_text", None)
        if text_payload:
            logger.debug("üìù Tentative de parsing depuis output_text")
            try:
                parsed = json.loads(text_payload)
                logger.debug("‚úÖ Parsing r√©ussi depuis output_text")
                return parsed
            except json.JSONDecodeError:
                logger.debug("‚ùå Le texte retourn√© par OpenAI n'est pas du JSON valide")

        logger.debug("üîç Tentative de parsing depuis model_dump()")
        try:
            raw = response.model_dump()
            logger.debug("‚úÖ model_dump() r√©ussi, type: %s", type(raw))
        except Exception as exc:  # pragma: no cover - defensive guard
            logger.debug("‚ùå model_dump() √©chou√©: %s", exc)
            raw = None

        if isinstance(raw, dict):
            logger.debug("üìä Analyse de la structure raw (dict)")
            outputs = raw.get("output") or []
            for block in outputs:
                for content in block.get("content", []):
                    if content.get("type") == "json":
                        logger.debug("‚úÖ Trouv√© un bloc de type 'json'")
                        candidate = content.get("json")
                        if isinstance(candidate, dict):
                            logger.debug("‚úÖ Parsing r√©ussi depuis bloc json")
                            return candidate
                        try:
                            return json.loads(json.dumps(candidate))
                        except (TypeError, ValueError):
                            continue
                    if content.get("type") in {"text", "output_text"} and content.get("text"):
                        logger.debug("üîç Tentative de parsing depuis bloc text/output_text")
                        try:
                            parsed = json.loads(content["text"])
                            logger.debug("‚úÖ Parsing r√©ussi depuis bloc text")
                            return parsed
                        except json.JSONDecodeError:
                            logger.debug("‚ùå Parsing JSON √©chou√© depuis bloc text")
                            continue

            choices = raw.get("choices") or []
            for choice in choices:
                message = choice.get("message") or {}
                text = message.get("content")
                if not text:
                    continue
                logger.debug("üîç Tentative de parsing depuis choices.message.content")
                try:
                    parsed = json.loads(text)
                    logger.debug("‚úÖ Parsing r√©ussi depuis choices")
                    return parsed
                except json.JSONDecodeError:
                    logger.debug("‚ùå Parsing JSON √©chou√© depuis choices")
                    continue

        logger.warning("‚ö†Ô∏è Impossible de parser la r√©ponse OpenAI avec toutes les m√©thodes")
        return None

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    def _request(self, url: str, params: Optional[dict[str, str]] = None) -> Optional[dict]:
        logger.debug("üåê Requ√™te HTTP vers: %s", url)
        logger.debug("üìã Param√®tres: %s", params)

        try:
            response = self.session.get(url, params=params, timeout=8)
            logger.debug("‚úÖ R√©ponse re√ßue - Status: %d", response.status_code)
        except requests.RequestException as exc:
            logger.warning("‚ùå Request to %s failed: %s", url, exc)
            return None

        if response.status_code != 200:
            logger.warning("‚ùå Request to %s failed with status %s", url, response.status_code)
            return None

        try:
            json_data = response.json()
            logger.debug("‚úÖ JSON d√©cod√© avec succ√®s")
            return json_data
        except json.JSONDecodeError:
            logger.warning("‚ùå Unable to decode JSON from %s", url)
            return None

    def _build_query(self, wine) -> str:
        logger.debug("üî® Construction de la requ√™te pour le vin: %s", wine.name)
        parts = [wine.name]
        extra_attrs = getattr(wine, "extra_attributes", {}) or {}

        year = extra_attrs.get("year")
        if year:
            parts.append(str(year))

        region = extra_attrs.get("region")
        if region:
            parts.append(region)

        grape = extra_attrs.get("grape")
        if grape:
            parts.append(grape)
        query = " ".join(filter(None, parts)).strip()
        logger.debug("‚úÖ Requ√™te construite: '%s'", query)
        return query

    @staticmethod
    def _clean_text(value: Optional[str]) -> str:
        if not value:
            return ""
        text = re.sub(r"\s+", " ", value).strip()
        return text

    @staticmethod
    def _truncate(value: str, max_length: int) -> str:
        if len(value) <= max_length:
            return value
        return value[: max_length - 1].rstrip() + "‚Ä¶"

    @staticmethod
    def _sanitize_text(value: Optional[str]) -> Optional[str]:
        if value is None:
            return None
        cleaned = bleach.clean(str(value), tags=[], attributes={}, strip=True).strip()
        return cleaned or None

    @classmethod
    def _sanitize_content(cls, value: Optional[str]) -> str:
        cleaned = cls._sanitize_text(value)
        return cleaned or ""

    @staticmethod
    def _sanitize_source_url(value: Optional[str]) -> Optional[str]:
        if not value:
            return None
        candidate = str(value).strip()
        parsed = urlparse(candidate)
        if parsed.scheme not in {"http", "https"}:
            return None
        if not parsed.netloc:
            return None
        return candidate

    def _log_openai_request_response(
        self,
        system_prompt: str,
        user_prompt: str,
        schema: dict,
        response,
        error: Optional[str]
    ) -> None:
        """Enregistre la requ√™te et la r√©ponse OpenAI dans un fichier JSON."""
        if not self.log_openai_payloads:
            return

        try:
            # Cr√©er le r√©pertoire si n√©cessaire
            log_dir = Path("logs/openai_responses")
            log_dir.mkdir(parents=True, exist_ok=True)

            # G√©n√©rer un nom de fichier unique avec timestamp
            timestamp = datetime.now()
            filename = timestamp.strftime("openai_%Y%m%d_%H%M%S_%f.json")
            filepath = log_dir / filename

            # Pr√©parer les donn√©es de log
            log_data = {
                "timestamp": timestamp.isoformat(),
                "model": self.openai_model,
                "request": {
                    "system_prompt": system_prompt,
                    "user_prompt": user_prompt,
                    "schema": schema
                },
                "response": {}
            }

            if error:
                log_data["response"]["error"] = error
                log_data["response"]["parsed_data"] = None
                logger.debug("üíæ Enregistrement de l'erreur OpenAI dans: %s", filepath)
            else:
                # Tenter de parser la r√©ponse
                parsed_data = self._parse_openai_payload(response)
                log_data["response"]["parsed_data"] = parsed_data

                # Ajouter la r√©ponse brute si disponible
                try:
                    log_data["response"]["raw"] = response.model_dump() if response else None
                except Exception:
                    log_data["response"]["raw"] = None

                log_data["response"]["error"] = None
                logger.debug("üíæ Enregistrement de la r√©ponse OpenAI dans: %s", filepath)

            # √âcrire le fichier JSON
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(log_data, f, indent=2, ensure_ascii=False)

            logger.info("‚úÖ Log OpenAI enregistr√©: %s", filepath)

        except Exception as exc:
            logger.error("‚ùå Erreur lors de l'enregistrement du log OpenAI: %s", exc)

    @staticmethod
    def _deduplicate(insights: Iterable[InsightData]) -> List[InsightData]:
        seen = set()
        result: List[InsightData] = []
        duplicates_count = 0
        for insight in insights:
            key = (
                insight.category,
                insight.title,
                insight.content,
                insight.source_url,
            )
            if key in seen:
                duplicates_count += 1
                continue
            seen.add(key)
            result.append(insight)

        if duplicates_count > 0:
            logger.debug("üîÑ D√©duplication: %d doublons supprim√©s", duplicates_count)

        return result
